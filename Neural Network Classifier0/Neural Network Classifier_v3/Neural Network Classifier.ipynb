{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version THree of our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture and training\n",
    "    process with regularization and callbacks to prevent overfitting and\n",
    "    optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        # This prevents overfitting and saves training time.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "            restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        # This can help the model find a better minimum in the loss function.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # Factor by which the learning rate will be reduced\n",
    "            patience=20, # Number of epochs with no improvement after which learning rate will be reduced\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization to prevent overfitting\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001))) # L2 regularization\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,  # Set a high number of epochs, but EarlyStopping will handle stopping\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            callbacks=[early_stopping, reduce_lr], # Pass the callbacks here\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example Usage: Uncomment the line below and provide the path to your CSV file\n",
    "# if __name__ == \"__main__\":\n",
    "#     perform_neural_network_classification(\"path/to/your/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1792      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18433 (72.00 KB)\n",
      "Trainable params: 18433 (72.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "200/200 [==============================] - 6s 8ms/step - loss: 0.8722 - accuracy: 0.5086 - val_loss: 0.8241 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7930 - accuracy: 0.5072 - val_loss: 0.7676 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7494 - accuracy: 0.5192 - val_loss: 0.7391 - val_accuracy: 0.4869 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7254 - accuracy: 0.5223 - val_loss: 0.7187 - val_accuracy: 0.5144 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7107 - accuracy: 0.5355 - val_loss: 0.7083 - val_accuracy: 0.5131 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7037 - accuracy: 0.5258 - val_loss: 0.7024 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.5272 - val_loss: 0.6992 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6972 - accuracy: 0.5252 - val_loss: 0.6978 - val_accuracy: 0.5175 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.5305 - val_loss: 0.6966 - val_accuracy: 0.5194 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6950 - accuracy: 0.5331 - val_loss: 0.6976 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6944 - accuracy: 0.5280 - val_loss: 0.6979 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6945 - accuracy: 0.5305 - val_loss: 0.6962 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6936 - accuracy: 0.5289 - val_loss: 0.6961 - val_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6934 - accuracy: 0.5347 - val_loss: 0.6994 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.6928 - accuracy: 0.5384 - val_loss: 0.6980 - val_accuracy: 0.4950 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.6935 - accuracy: 0.5377 - val_loss: 0.6989 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5375 - val_loss: 0.6979 - val_accuracy: 0.5113 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.5394 - val_loss: 0.6978 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6928 - accuracy: 0.5409 - val_loss: 0.7011 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 0.6931 - accuracy: 0.5378 - val_loss: 0.6980 - val_accuracy: 0.4981 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6934 - accuracy: 0.5416 - val_loss: 0.6994 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.5358 - val_loss: 0.6989 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5502 - val_loss: 0.7022 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6930 - accuracy: 0.5395 - val_loss: 0.7019 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5425 - val_loss: 0.6988 - val_accuracy: 0.5019 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6926 - accuracy: 0.5445 - val_loss: 0.6983 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.5461 - val_loss: 0.6986 - val_accuracy: 0.5156 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5412 - val_loss: 0.7013 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5448 - val_loss: 0.7004 - val_accuracy: 0.5025 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6908 - accuracy: 0.5444 - val_loss: 0.6992 - val_accuracy: 0.5250 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6919 - accuracy: 0.5445 - val_loss: 0.7011 - val_accuracy: 0.5044 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5408 - val_loss: 0.7025 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6910 - accuracy: 0.5514 - val_loss: 0.7006 - val_accuracy: 0.5019 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6892 - accuracy: 0.5494 - val_loss: 0.7012 - val_accuracy: 0.5013 - lr: 2.0000e-04\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6895 - accuracy: 0.5512 - val_loss: 0.7020 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.5534 - val_loss: 0.7032 - val_accuracy: 0.5013 - lr: 2.0000e-04\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.5550 - val_loss: 0.7034 - val_accuracy: 0.5044 - lr: 2.0000e-04\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.5567 - val_loss: 0.7052 - val_accuracy: 0.5038 - lr: 2.0000e-04\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.5530 - val_loss: 0.7021 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.5592 - val_loss: 0.7025 - val_accuracy: 0.5119 - lr: 2.0000e-04\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.5592 - val_loss: 0.7038 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6876 - accuracy: 0.5561 - val_loss: 0.7043 - val_accuracy: 0.5100 - lr: 2.0000e-04\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.5500 - val_loss: 0.7027 - val_accuracy: 0.5081 - lr: 2.0000e-04\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.5634 - val_loss: 0.7058 - val_accuracy: 0.5038 - lr: 2.0000e-04\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6883 - accuracy: 0.5578 - val_loss: 0.7034 - val_accuracy: 0.5144 - lr: 2.0000e-04\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.5652 - val_loss: 0.7051 - val_accuracy: 0.5106 - lr: 2.0000e-04\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6890 - accuracy: 0.5562 - val_loss: 0.7032 - val_accuracy: 0.5100 - lr: 2.0000e-04\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6881 - accuracy: 0.5619 - val_loss: 0.7053 - val_accuracy: 0.5094 - lr: 2.0000e-04\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.5569 - val_loss: 0.7051 - val_accuracy: 0.5119 - lr: 2.0000e-04\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6887 - accuracy: 0.5661 - val_loss: 0.7049 - val_accuracy: 0.5113 - lr: 2.0000e-04\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6872 - accuracy: 0.5636 - val_loss: 0.7067 - val_accuracy: 0.5063 - lr: 2.0000e-04\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.5608 - val_loss: 0.7032 - val_accuracy: 0.5025 - lr: 2.0000e-04\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6872 - accuracy: 0.5612 - val_loss: 0.7055 - val_accuracy: 0.5094 - lr: 2.0000e-04\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.5600 - val_loss: 0.7055 - val_accuracy: 0.5125 - lr: 4.0000e-05\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6879 - accuracy: 0.5587 - val_loss: 0.7055 - val_accuracy: 0.5138 - lr: 4.0000e-05\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6874 - accuracy: 0.5627 - val_loss: 0.7054 - val_accuracy: 0.5119 - lr: 4.0000e-05\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6865 - accuracy: 0.5670 - val_loss: 0.7057 - val_accuracy: 0.5125 - lr: 4.0000e-05\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6856 - accuracy: 0.5661 - val_loss: 0.7057 - val_accuracy: 0.5119 - lr: 4.0000e-05\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.5575 - val_loss: 0.7054 - val_accuracy: 0.5106 - lr: 4.0000e-05\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.5603 - val_loss: 0.7059 - val_accuracy: 0.5131 - lr: 4.0000e-05\n",
      "Epoch 61/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.5648 - val_loss: 0.7056 - val_accuracy: 0.5119 - lr: 4.0000e-05\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6863 - accuracy: 0.5655 - val_loss: 0.7057 - val_accuracy: 0.5125 - lr: 4.0000e-05\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6877 - accuracy: 0.5575 - val_loss: 0.7058 - val_accuracy: 0.5125 - lr: 4.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.4995\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.23      0.31       989\n",
      "         1.0       0.50      0.77      0.61      1011\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.50      0.50      0.46      2000\n",
      "weighted avg       0.50      0.50      0.46      2000\n",
      "\n",
      "ROC AUC Score: 0.5067\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0023\n",
      "Mean Absolute Error (MAE): 0.4997\n",
      "Mean Squared Error (MSE): 0.2505\n",
      "Root Mean Squared Error (RMSE): 0.5005\n",
      "Mean Absolute Percentage Error (MAPE): 2557396826.85%\n",
      "Mean Squared Log Error (MSLE): 0.1247\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

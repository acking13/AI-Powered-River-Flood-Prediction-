{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version Four of our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture and training\n",
    "    process with regularization and callbacks to prevent overfitting and\n",
    "    optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        # This prevents overfitting and saves training time.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "            restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        # This can help the model find a better minimum in the loss function.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # Factor by which the learning rate will be reduced\n",
    "            patience=20, # Number of epochs with no improvement after which learning rate will be reduced\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization to prevent overfitting\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001))) # L2 regularization\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "\n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,  # Set a high number of epochs, but EarlyStopping will handle stopping\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            callbacks=[early_stopping, reduce_lr], # Pass the callbacks here\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example Usage: Uncomment the line below and provide the path to your CSV file\n",
    "# if __name__ == \"__main__\":\n",
    "#     perform_neural_network_classification(\"path/to/your/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1792      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30913 (120.75 KB)\n",
      "Trainable params: 30913 (120.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "200/200 [==============================] - 7s 8ms/step - loss: 0.8841 - accuracy: 0.4866 - val_loss: 0.7469 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7141 - accuracy: 0.4888 - val_loss: 0.6983 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.4931 - val_loss: 0.6938 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6934 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.4872 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6932 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 2.0000e-04\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 61/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 64/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 65/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 66/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 67/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 68/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 69/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 4.0000e-05\n",
      "Epoch 70/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 71/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 72/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 73/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 74/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 75/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 76/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 77/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "Epoch 78/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6930 - val_accuracy: 0.5238 - lr: 1.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.5055\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       989\n",
      "         1.0       0.51      1.00      0.67      1011\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.25      0.50      0.34      2000\n",
      "weighted avg       0.26      0.51      0.34      2000\n",
      "\n",
      "ROC AUC Score: 0.5000\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0000\n",
      "Mean Absolute Error (MAE): 0.5000\n",
      "Mean Squared Error (MSE): 0.2500\n",
      "Root Mean Squared Error (RMSE): 0.5000\n",
      "Mean Absolute Percentage Error (MAPE): 2482893911.73%\n",
      "Mean Squared Log Error (MSLE): 0.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acking\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\acking\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\acking\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version twoof our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture with Batch Normalization\n",
    "    and an additional hidden layer to prevent overfitting and optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=20,\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        # Added Batch Normalization and a third hidden layer for a deeper network\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001)))\n",
    "        model.add(BatchNormalization()) # Added Batch Normalization layer\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "        model.add(BatchNormalization()) # Added Batch Normalization layer\n",
    "        model.add(Dropout(0.3)) # Adjusted dropout rate slightly\n",
    "        \n",
    "        # Third hidden layer\n",
    "        model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "        model.add(BatchNormalization()) # Added Batch Normalization layer\n",
    "\n",
    "        # Output layer for binary classification\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example Usage: Uncomment the line below and provide the path to your CSV file\n",
    "# if __name__ == \"__main__\":\n",
    "#     perform_neural_network_classification(\"path/to/your/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1792      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13057 (51.00 KB)\n",
      "Trainable params: 12609 (49.25 KB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "200/200 [==============================] - 8s 9ms/step - loss: 0.9112 - accuracy: 0.5084 - val_loss: 0.8467 - val_accuracy: 0.5069 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8632 - accuracy: 0.5097 - val_loss: 0.8424 - val_accuracy: 0.5094 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8436 - accuracy: 0.5138 - val_loss: 0.8381 - val_accuracy: 0.4913 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8327 - accuracy: 0.5178 - val_loss: 0.8270 - val_accuracy: 0.4919 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8213 - accuracy: 0.5203 - val_loss: 0.8180 - val_accuracy: 0.4969 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8086 - accuracy: 0.5252 - val_loss: 0.8090 - val_accuracy: 0.5006 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7998 - accuracy: 0.5333 - val_loss: 0.7999 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7899 - accuracy: 0.5312 - val_loss: 0.7969 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7825 - accuracy: 0.5384 - val_loss: 0.7858 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.7769 - accuracy: 0.5284 - val_loss: 0.7786 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.7675 - accuracy: 0.5444 - val_loss: 0.7711 - val_accuracy: 0.5094 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7619 - accuracy: 0.5436 - val_loss: 0.7634 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7554 - accuracy: 0.5394 - val_loss: 0.7572 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7521 - accuracy: 0.5406 - val_loss: 0.7551 - val_accuracy: 0.5013 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7440 - accuracy: 0.5495 - val_loss: 0.7512 - val_accuracy: 0.5175 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7390 - accuracy: 0.5564 - val_loss: 0.7468 - val_accuracy: 0.5312 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7352 - accuracy: 0.5544 - val_loss: 0.7416 - val_accuracy: 0.5225 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7328 - accuracy: 0.5466 - val_loss: 0.7382 - val_accuracy: 0.5263 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7288 - accuracy: 0.5525 - val_loss: 0.7356 - val_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.7275 - accuracy: 0.5406 - val_loss: 0.7355 - val_accuracy: 0.5144 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7240 - accuracy: 0.5517 - val_loss: 0.7345 - val_accuracy: 0.5263 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7198 - accuracy: 0.5473 - val_loss: 0.7281 - val_accuracy: 0.5188 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7177 - accuracy: 0.5627 - val_loss: 0.7258 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7144 - accuracy: 0.5639 - val_loss: 0.7270 - val_accuracy: 0.5319 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7147 - accuracy: 0.5584 - val_loss: 0.7241 - val_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7134 - accuracy: 0.5566 - val_loss: 0.7253 - val_accuracy: 0.5163 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7114 - accuracy: 0.5589 - val_loss: 0.7277 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7083 - accuracy: 0.5722 - val_loss: 0.7226 - val_accuracy: 0.5325 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7115 - accuracy: 0.5606 - val_loss: 0.7235 - val_accuracy: 0.5094 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7078 - accuracy: 0.5609 - val_loss: 0.7221 - val_accuracy: 0.5131 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.7045 - accuracy: 0.5708 - val_loss: 0.7245 - val_accuracy: 0.5219 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7065 - accuracy: 0.5663 - val_loss: 0.7255 - val_accuracy: 0.4988 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.7075 - accuracy: 0.5630 - val_loss: 0.7259 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.7030 - accuracy: 0.5763 - val_loss: 0.7220 - val_accuracy: 0.5088 - lr: 0.0010\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.7017 - accuracy: 0.5733 - val_loss: 0.7239 - val_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7043 - accuracy: 0.5719 - val_loss: 0.7213 - val_accuracy: 0.5194 - lr: 0.0010\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7012 - accuracy: 0.5763 - val_loss: 0.7172 - val_accuracy: 0.5387 - lr: 0.0010\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7020 - accuracy: 0.5706 - val_loss: 0.7208 - val_accuracy: 0.5206 - lr: 0.0010\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7036 - accuracy: 0.5730 - val_loss: 0.7224 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7006 - accuracy: 0.5770 - val_loss: 0.7249 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7012 - accuracy: 0.5747 - val_loss: 0.7231 - val_accuracy: 0.5244 - lr: 0.0010\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7024 - accuracy: 0.5700 - val_loss: 0.7225 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.5808 - val_loss: 0.7247 - val_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6994 - accuracy: 0.5728 - val_loss: 0.7199 - val_accuracy: 0.5300 - lr: 0.0010\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7021 - accuracy: 0.5697 - val_loss: 0.7218 - val_accuracy: 0.5194 - lr: 0.0010\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6962 - accuracy: 0.5788 - val_loss: 0.7244 - val_accuracy: 0.5156 - lr: 0.0010\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.5716 - val_loss: 0.7221 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.5797 - val_loss: 0.7246 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6949 - accuracy: 0.5863 - val_loss: 0.7266 - val_accuracy: 0.5175 - lr: 0.0010\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6939 - accuracy: 0.5764 - val_loss: 0.7264 - val_accuracy: 0.5306 - lr: 0.0010\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6961 - accuracy: 0.5805 - val_loss: 0.7292 - val_accuracy: 0.5369 - lr: 0.0010\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6946 - accuracy: 0.5786 - val_loss: 0.7280 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6985 - accuracy: 0.5752 - val_loss: 0.7242 - val_accuracy: 0.5144 - lr: 0.0010\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6950 - accuracy: 0.5809 - val_loss: 0.7248 - val_accuracy: 0.5188 - lr: 0.0010\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6981 - accuracy: 0.5797 - val_loss: 0.7283 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.5828 - val_loss: 0.7303 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6947 - accuracy: 0.5838 - val_loss: 0.7303 - val_accuracy: 0.5063 - lr: 0.0010\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6864 - accuracy: 0.6014 - val_loss: 0.7332 - val_accuracy: 0.5100 - lr: 2.0000e-04\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6875 - accuracy: 0.5950 - val_loss: 0.7334 - val_accuracy: 0.5131 - lr: 2.0000e-04\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6800 - accuracy: 0.6062 - val_loss: 0.7355 - val_accuracy: 0.5088 - lr: 2.0000e-04\n",
      "Epoch 61/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6807 - accuracy: 0.6052 - val_loss: 0.7372 - val_accuracy: 0.5138 - lr: 2.0000e-04\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6798 - accuracy: 0.6092 - val_loss: 0.7385 - val_accuracy: 0.5125 - lr: 2.0000e-04\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6798 - accuracy: 0.6092 - val_loss: 0.7375 - val_accuracy: 0.5188 - lr: 2.0000e-04\n",
      "Epoch 64/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6802 - accuracy: 0.6070 - val_loss: 0.7384 - val_accuracy: 0.5113 - lr: 2.0000e-04\n",
      "Epoch 65/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6769 - accuracy: 0.6073 - val_loss: 0.7372 - val_accuracy: 0.5125 - lr: 2.0000e-04\n",
      "Epoch 66/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6745 - accuracy: 0.6127 - val_loss: 0.7403 - val_accuracy: 0.5031 - lr: 2.0000e-04\n",
      "Epoch 67/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6742 - accuracy: 0.6105 - val_loss: 0.7404 - val_accuracy: 0.5063 - lr: 2.0000e-04\n",
      "Epoch 68/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6720 - accuracy: 0.6162 - val_loss: 0.7421 - val_accuracy: 0.5006 - lr: 2.0000e-04\n",
      "Epoch 69/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6681 - accuracy: 0.6219 - val_loss: 0.7439 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 70/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6734 - accuracy: 0.6131 - val_loss: 0.7432 - val_accuracy: 0.5169 - lr: 2.0000e-04\n",
      "Epoch 71/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6712 - accuracy: 0.6161 - val_loss: 0.7448 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 72/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6665 - accuracy: 0.6248 - val_loss: 0.7455 - val_accuracy: 0.5125 - lr: 2.0000e-04\n",
      "Epoch 73/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6643 - accuracy: 0.6214 - val_loss: 0.7485 - val_accuracy: 0.4994 - lr: 2.0000e-04\n",
      "Epoch 74/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6692 - accuracy: 0.6144 - val_loss: 0.7508 - val_accuracy: 0.5113 - lr: 2.0000e-04\n",
      "Epoch 75/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6677 - accuracy: 0.6172 - val_loss: 0.7505 - val_accuracy: 0.5138 - lr: 2.0000e-04\n",
      "Epoch 76/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6639 - accuracy: 0.6228 - val_loss: 0.7518 - val_accuracy: 0.5050 - lr: 2.0000e-04\n",
      "Epoch 77/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6655 - accuracy: 0.6203 - val_loss: 0.7538 - val_accuracy: 0.5119 - lr: 2.0000e-04\n",
      "Epoch 78/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6627 - accuracy: 0.6245 - val_loss: 0.7522 - val_accuracy: 0.5125 - lr: 4.0000e-05\n",
      "Epoch 79/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6643 - accuracy: 0.6230 - val_loss: 0.7528 - val_accuracy: 0.5131 - lr: 4.0000e-05\n",
      "Epoch 80/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6579 - accuracy: 0.6300 - val_loss: 0.7540 - val_accuracy: 0.5094 - lr: 4.0000e-05\n",
      "Epoch 81/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6613 - accuracy: 0.6273 - val_loss: 0.7540 - val_accuracy: 0.5056 - lr: 4.0000e-05\n",
      "Epoch 82/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6570 - accuracy: 0.6380 - val_loss: 0.7551 - val_accuracy: 0.5075 - lr: 4.0000e-05\n",
      "Epoch 83/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6580 - accuracy: 0.6309 - val_loss: 0.7555 - val_accuracy: 0.5081 - lr: 4.0000e-05\n",
      "Epoch 84/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6558 - accuracy: 0.6322 - val_loss: 0.7558 - val_accuracy: 0.5069 - lr: 4.0000e-05\n",
      "Epoch 85/2000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6528 - accuracy: 0.6425 - val_loss: 0.7577 - val_accuracy: 0.5031 - lr: 4.0000e-05\n",
      "Epoch 86/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6546 - accuracy: 0.6386 - val_loss: 0.7568 - val_accuracy: 0.5081 - lr: 4.0000e-05\n",
      "Epoch 87/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6555 - accuracy: 0.6397 - val_loss: 0.7580 - val_accuracy: 0.5063 - lr: 4.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "63/63 [==============================] - 1s 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.5135\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.45      0.48       989\n",
      "         1.0       0.52      0.57      0.54      1011\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.51      0.51      0.51      2000\n",
      "weighted avg       0.51      0.51      0.51      2000\n",
      "\n",
      "ROC AUC Score: 0.5114\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0195\n",
      "Mean Absolute Error (MAE): 0.4986\n",
      "Mean Squared Error (MSE): 0.2549\n",
      "Root Mean Squared Error (RMSE): 0.5048\n",
      "Mean Absolute Percentage Error (MAPE): 2526465337.14%\n",
      "Mean Squared Log Error (MSLE): 0.1261\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

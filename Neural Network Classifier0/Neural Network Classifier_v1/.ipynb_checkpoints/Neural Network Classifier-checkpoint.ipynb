{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version one of our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture and training\n",
    "    process with regularization and callbacks to prevent overfitting and\n",
    "    optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        # This prevents overfitting and saves training time.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "            restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        # This can help the model find a better minimum in the loss function.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # Factor by which the learning rate will be reduced\n",
    "            patience=20, # Number of epochs with no improvement after which learning rate will be reduced\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization to prevent overfitting\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001))) # L2 regularization\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,  # Set a high number of epochs, but EarlyStopping will handle stopping\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            callbacks=[early_stopping, reduce_lr], # Pass the callbacks here\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example Usage: Uncomment the line below and provide the path to your CSV file\n",
    "# if __name__ == \"__main__\":\n",
    "#     perform_neural_network_classification(\"path/to/your/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10113 (39.50 KB)\n",
      "Trainable params: 10113 (39.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "200/200 [==============================] - 3s 6ms/step - loss: 0.7997 - accuracy: 0.5089 - val_loss: 0.7767 - val_accuracy: 0.5194 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7679 - accuracy: 0.5095 - val_loss: 0.7589 - val_accuracy: 0.5069 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7503 - accuracy: 0.5272 - val_loss: 0.7444 - val_accuracy: 0.5119 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7365 - accuracy: 0.5325 - val_loss: 0.7369 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7265 - accuracy: 0.5297 - val_loss: 0.7296 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7193 - accuracy: 0.5348 - val_loss: 0.7211 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7129 - accuracy: 0.5530 - val_loss: 0.7161 - val_accuracy: 0.5200 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7094 - accuracy: 0.5361 - val_loss: 0.7132 - val_accuracy: 0.5069 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7045 - accuracy: 0.5442 - val_loss: 0.7098 - val_accuracy: 0.5056 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7022 - accuracy: 0.5462 - val_loss: 0.7067 - val_accuracy: 0.5213 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7004 - accuracy: 0.5433 - val_loss: 0.7048 - val_accuracy: 0.5106 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6986 - accuracy: 0.5481 - val_loss: 0.7050 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6962 - accuracy: 0.5453 - val_loss: 0.7040 - val_accuracy: 0.5088 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6973 - accuracy: 0.5409 - val_loss: 0.7027 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6949 - accuracy: 0.5544 - val_loss: 0.7010 - val_accuracy: 0.5056 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6948 - accuracy: 0.5489 - val_loss: 0.7039 - val_accuracy: 0.5013 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6944 - accuracy: 0.5473 - val_loss: 0.7001 - val_accuracy: 0.5100 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5494 - val_loss: 0.6997 - val_accuracy: 0.5200 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.5480 - val_loss: 0.7010 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5502 - val_loss: 0.7014 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.5583 - val_loss: 0.6996 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5516 - val_loss: 0.7010 - val_accuracy: 0.5188 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.5587 - val_loss: 0.6993 - val_accuracy: 0.5194 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.5519 - val_loss: 0.7000 - val_accuracy: 0.5188 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6915 - accuracy: 0.5534 - val_loss: 0.7033 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.5555 - val_loss: 0.7022 - val_accuracy: 0.5006 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.5595 - val_loss: 0.7021 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6902 - accuracy: 0.5619 - val_loss: 0.7024 - val_accuracy: 0.5219 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5550 - val_loss: 0.7043 - val_accuracy: 0.4975 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6891 - accuracy: 0.5586 - val_loss: 0.7024 - val_accuracy: 0.5056 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6902 - accuracy: 0.5569 - val_loss: 0.7026 - val_accuracy: 0.5125 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6890 - accuracy: 0.5561 - val_loss: 0.7033 - val_accuracy: 0.5138 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5578 - val_loss: 0.7033 - val_accuracy: 0.5100 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.5561 - val_loss: 0.7047 - val_accuracy: 0.5038 - lr: 0.0010\n",
      "Epoch 35/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6894 - accuracy: 0.5667 - val_loss: 0.7076 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 36/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6900 - accuracy: 0.5627 - val_loss: 0.7066 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 37/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6874 - accuracy: 0.5691 - val_loss: 0.7080 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 38/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6890 - accuracy: 0.5625 - val_loss: 0.7082 - val_accuracy: 0.4994 - lr: 0.0010\n",
      "Epoch 39/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6888 - accuracy: 0.5666 - val_loss: 0.7069 - val_accuracy: 0.5081 - lr: 0.0010\n",
      "Epoch 40/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6889 - accuracy: 0.5638 - val_loss: 0.7077 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 41/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6876 - accuracy: 0.5733 - val_loss: 0.7084 - val_accuracy: 0.5019 - lr: 0.0010\n",
      "Epoch 42/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6869 - accuracy: 0.5717 - val_loss: 0.7105 - val_accuracy: 0.4900 - lr: 0.0010\n",
      "Epoch 43/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6866 - accuracy: 0.5756 - val_loss: 0.7114 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 44/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6840 - accuracy: 0.5803 - val_loss: 0.7082 - val_accuracy: 0.5000 - lr: 2.0000e-04\n",
      "Epoch 45/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6829 - accuracy: 0.5798 - val_loss: 0.7082 - val_accuracy: 0.5081 - lr: 2.0000e-04\n",
      "Epoch 46/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6806 - accuracy: 0.5867 - val_loss: 0.7086 - val_accuracy: 0.5038 - lr: 2.0000e-04\n",
      "Epoch 47/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6809 - accuracy: 0.5831 - val_loss: 0.7096 - val_accuracy: 0.5025 - lr: 2.0000e-04\n",
      "Epoch 48/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6797 - accuracy: 0.5906 - val_loss: 0.7104 - val_accuracy: 0.5013 - lr: 2.0000e-04\n",
      "Epoch 49/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6809 - accuracy: 0.5798 - val_loss: 0.7105 - val_accuracy: 0.5056 - lr: 2.0000e-04\n",
      "Epoch 50/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6797 - accuracy: 0.5892 - val_loss: 0.7108 - val_accuracy: 0.5006 - lr: 2.0000e-04\n",
      "Epoch 51/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6770 - accuracy: 0.5897 - val_loss: 0.7108 - val_accuracy: 0.5056 - lr: 2.0000e-04\n",
      "Epoch 52/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.5881 - val_loss: 0.7116 - val_accuracy: 0.5081 - lr: 2.0000e-04\n",
      "Epoch 53/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6778 - accuracy: 0.5878 - val_loss: 0.7129 - val_accuracy: 0.5050 - lr: 2.0000e-04\n",
      "Epoch 54/2000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6781 - accuracy: 0.5905 - val_loss: 0.7120 - val_accuracy: 0.5088 - lr: 2.0000e-04\n",
      "Epoch 55/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.5928 - val_loss: 0.7125 - val_accuracy: 0.5181 - lr: 2.0000e-04\n",
      "Epoch 56/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6786 - accuracy: 0.5902 - val_loss: 0.7123 - val_accuracy: 0.5069 - lr: 2.0000e-04\n",
      "Epoch 57/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6790 - accuracy: 0.5894 - val_loss: 0.7133 - val_accuracy: 0.5081 - lr: 2.0000e-04\n",
      "Epoch 58/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6785 - accuracy: 0.5980 - val_loss: 0.7132 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 59/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6781 - accuracy: 0.5966 - val_loss: 0.7131 - val_accuracy: 0.5031 - lr: 2.0000e-04\n",
      "Epoch 60/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6777 - accuracy: 0.5983 - val_loss: 0.7142 - val_accuracy: 0.5025 - lr: 2.0000e-04\n",
      "Epoch 61/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6772 - accuracy: 0.5911 - val_loss: 0.7138 - val_accuracy: 0.5019 - lr: 2.0000e-04\n",
      "Epoch 62/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6779 - accuracy: 0.5916 - val_loss: 0.7137 - val_accuracy: 0.5075 - lr: 2.0000e-04\n",
      "Epoch 63/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6768 - accuracy: 0.5947 - val_loss: 0.7145 - val_accuracy: 0.5044 - lr: 2.0000e-04\n",
      "Epoch 64/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6751 - accuracy: 0.5916 - val_loss: 0.7145 - val_accuracy: 0.5006 - lr: 4.0000e-05\n",
      "Epoch 65/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6760 - accuracy: 0.6005 - val_loss: 0.7143 - val_accuracy: 0.5013 - lr: 4.0000e-05\n",
      "Epoch 66/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6745 - accuracy: 0.5964 - val_loss: 0.7146 - val_accuracy: 0.5038 - lr: 4.0000e-05\n",
      "Epoch 67/2000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.5962 - val_loss: 0.7144 - val_accuracy: 0.5013 - lr: 4.0000e-05\n",
      "Epoch 68/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6745 - accuracy: 0.6008 - val_loss: 0.7144 - val_accuracy: 0.5019 - lr: 4.0000e-05\n",
      "Epoch 69/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6760 - accuracy: 0.5994 - val_loss: 0.7148 - val_accuracy: 0.5025 - lr: 4.0000e-05\n",
      "Epoch 70/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6741 - accuracy: 0.5981 - val_loss: 0.7148 - val_accuracy: 0.5044 - lr: 4.0000e-05\n",
      "Epoch 71/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6737 - accuracy: 0.6022 - val_loss: 0.7148 - val_accuracy: 0.5025 - lr: 4.0000e-05\n",
      "Epoch 72/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6740 - accuracy: 0.6005 - val_loss: 0.7148 - val_accuracy: 0.5019 - lr: 4.0000e-05\n",
      "Epoch 73/2000\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6726 - accuracy: 0.6080 - val_loss: 0.7151 - val_accuracy: 0.5006 - lr: 4.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.31      0.38       989\n",
      "         1.0       0.50      0.69      0.58      1011\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.50      0.50      0.48      2000\n",
      "weighted avg       0.50      0.50      0.48      2000\n",
      "\n",
      "ROC AUC Score: 0.4999\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0077\n",
      "Mean Absolute Error (MAE): 0.4998\n",
      "Mean Squared Error (MSE): 0.2519\n",
      "Root Mean Squared Error (RMSE): 0.5019\n",
      "Mean Absolute Percentage Error (MAPE): 2558846902.80%\n",
      "Mean Squared Log Error (MSLE): 0.1253\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

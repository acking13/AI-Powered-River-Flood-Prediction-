{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74da2e09-dd45-41f9-bb04-55a1a02d702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification metrics, generates a confusion matrix heatmap,\n",
    "    and saves the metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Neural Network Model Setup ---\n",
    "        # Define a sequential neural network model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with 64 neurons and ReLU activation\n",
    "        model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Second hidden layer with 32 neurons and ReLU activation\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        # Sigmoid function squashes the output to a probability between 0 and 1\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        # Binary cross-entropy is the standard loss function for binary classification\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=50,  # Number of training epochs\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "        # --- 2. Save Metrics to Excel ---\n",
    "        # Create a dictionary to hold the metrics\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC Score'],\n",
    "            'Value': [accuracy, roc_auc]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_classification_performance.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 3. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f4ca6b-2142-4893-a88f-6444bc5195e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3009 (11.75 KB)\n",
      "Trainable params: 3009 (11.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\acking\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "200/200 [==============================] - 4s 6ms/step - loss: 0.6999 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.4969\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5181 - val_loss: 0.6962 - val_accuracy: 0.4881\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6972 - val_accuracy: 0.4944\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6889 - accuracy: 0.5394 - val_loss: 0.6975 - val_accuracy: 0.4825\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.5334 - val_loss: 0.6956 - val_accuracy: 0.4981\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6883 - accuracy: 0.5405 - val_loss: 0.6947 - val_accuracy: 0.5113\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6898 - accuracy: 0.5452 - val_loss: 0.6956 - val_accuracy: 0.5025\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6872 - accuracy: 0.5441 - val_loss: 0.6958 - val_accuracy: 0.4931\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5522 - val_loss: 0.6954 - val_accuracy: 0.4981\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6851 - accuracy: 0.5508 - val_loss: 0.6957 - val_accuracy: 0.5025\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6831 - accuracy: 0.5583 - val_loss: 0.6972 - val_accuracy: 0.5063\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6825 - accuracy: 0.5547 - val_loss: 0.6964 - val_accuracy: 0.5056\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6806 - accuracy: 0.5609 - val_loss: 0.6973 - val_accuracy: 0.4956\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6805 - accuracy: 0.5598 - val_loss: 0.6997 - val_accuracy: 0.5138\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.5641 - val_loss: 0.6980 - val_accuracy: 0.5106\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6796 - accuracy: 0.5595 - val_loss: 0.6992 - val_accuracy: 0.5131\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.5577 - val_loss: 0.6982 - val_accuracy: 0.5113\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6777 - accuracy: 0.5694 - val_loss: 0.6988 - val_accuracy: 0.5138\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6787 - accuracy: 0.5645 - val_loss: 0.6971 - val_accuracy: 0.5181\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6777 - accuracy: 0.5663 - val_loss: 0.6975 - val_accuracy: 0.5231\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6731 - accuracy: 0.5800 - val_loss: 0.6989 - val_accuracy: 0.5213\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6751 - accuracy: 0.5734 - val_loss: 0.6987 - val_accuracy: 0.5150\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6731 - accuracy: 0.5784 - val_loss: 0.6994 - val_accuracy: 0.5113\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6715 - accuracy: 0.5839 - val_loss: 0.7010 - val_accuracy: 0.5063\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6716 - accuracy: 0.5758 - val_loss: 0.7027 - val_accuracy: 0.5075\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6714 - accuracy: 0.5791 - val_loss: 0.7011 - val_accuracy: 0.5094\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6696 - accuracy: 0.5806 - val_loss: 0.7028 - val_accuracy: 0.5094\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6725 - accuracy: 0.5892 - val_loss: 0.7034 - val_accuracy: 0.5088\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6686 - accuracy: 0.5911 - val_loss: 0.7036 - val_accuracy: 0.5100\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6697 - accuracy: 0.5822 - val_loss: 0.7038 - val_accuracy: 0.5144\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6665 - accuracy: 0.5959 - val_loss: 0.7043 - val_accuracy: 0.5081\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6667 - accuracy: 0.5913 - val_loss: 0.7037 - val_accuracy: 0.5075\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6661 - accuracy: 0.5902 - val_loss: 0.7059 - val_accuracy: 0.5075\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6657 - accuracy: 0.5920 - val_loss: 0.7081 - val_accuracy: 0.5025\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6656 - accuracy: 0.5875 - val_loss: 0.7072 - val_accuracy: 0.5050\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6638 - accuracy: 0.5964 - val_loss: 0.7069 - val_accuracy: 0.5044\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6632 - accuracy: 0.5902 - val_loss: 0.7055 - val_accuracy: 0.5025\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.5991 - val_loss: 0.7074 - val_accuracy: 0.5006\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6620 - accuracy: 0.5981 - val_loss: 0.7090 - val_accuracy: 0.5038\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.5983 - val_loss: 0.7113 - val_accuracy: 0.5088\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6635 - accuracy: 0.5975 - val_loss: 0.7094 - val_accuracy: 0.4975\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6604 - accuracy: 0.6016 - val_loss: 0.7095 - val_accuracy: 0.5106\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6559 - accuracy: 0.6081 - val_loss: 0.7123 - val_accuracy: 0.5038\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6583 - accuracy: 0.6012 - val_loss: 0.7151 - val_accuracy: 0.4988\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6614 - accuracy: 0.5964 - val_loss: 0.7126 - val_accuracy: 0.4988\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6569 - accuracy: 0.5973 - val_loss: 0.7124 - val_accuracy: 0.5025\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6543 - accuracy: 0.6153 - val_loss: 0.7136 - val_accuracy: 0.5063\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6567 - accuracy: 0.6064 - val_loss: 0.7113 - val_accuracy: 0.5031\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6530 - accuracy: 0.6091 - val_loss: 0.7119 - val_accuracy: 0.5063\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6596 - accuracy: 0.6003 - val_loss: 0.7104 - val_accuracy: 0.5219\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.4955\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.36      0.41       989\n",
      "         1.0       0.50      0.63      0.56      1011\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.49      0.49      0.48      2000\n",
      "weighted avg       0.49      0.50      0.49      2000\n",
      "\n",
      "ROC AUC Score: 0.4979\n",
      "\n",
      "Model performance metrics saved to 'nn_classification_performance.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3b3f7a-b8fb-436d-b5a4-324deb0cfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Neural Network Model Setup ---\n",
    "        # Define a more complex sequential neural network model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with 128 neurons and ReLU activation\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer with 64 neurons and ReLU activation\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with more epochs\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=100,  # Increased number of training epochs\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        # Add a small value to predictions to avoid log(0)\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        # Create a dictionary to hold the metrics\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc1106-a06c-4892-812c-bdd6ed680562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10113 (39.50 KB)\n",
      "Trainable params: 10113 (39.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 3s 5ms/step - loss: 0.7022 - accuracy: 0.4981 - val_loss: 0.6967 - val_accuracy: 0.4969\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6948 - accuracy: 0.5148 - val_loss: 0.6967 - val_accuracy: 0.5150\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6925 - accuracy: 0.5241 - val_loss: 0.6964 - val_accuracy: 0.5013\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6884 - accuracy: 0.5409 - val_loss: 0.6941 - val_accuracy: 0.5206\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6889 - accuracy: 0.5330 - val_loss: 0.6935 - val_accuracy: 0.5238\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6853 - accuracy: 0.5525 - val_loss: 0.6958 - val_accuracy: 0.5113\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6849 - accuracy: 0.5517 - val_loss: 0.6956 - val_accuracy: 0.5163\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6855 - accuracy: 0.5569 - val_loss: 0.6941 - val_accuracy: 0.5131\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.5608 - val_loss: 0.6957 - val_accuracy: 0.5094\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6803 - accuracy: 0.5634 - val_loss: 0.6963 - val_accuracy: 0.5138\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6815 - accuracy: 0.5612 - val_loss: 0.6974 - val_accuracy: 0.5231\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.5622 - val_loss: 0.6959 - val_accuracy: 0.5156\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.5625 - val_loss: 0.6978 - val_accuracy: 0.5231\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6788 - accuracy: 0.5653 - val_loss: 0.6957 - val_accuracy: 0.5256\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6771 - accuracy: 0.5713 - val_loss: 0.6966 - val_accuracy: 0.5188\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.5614 - val_loss: 0.6990 - val_accuracy: 0.5225\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6761 - accuracy: 0.5788 - val_loss: 0.6978 - val_accuracy: 0.5100\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6742 - accuracy: 0.5780 - val_loss: 0.6997 - val_accuracy: 0.5006\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6733 - accuracy: 0.5781 - val_loss: 0.7021 - val_accuracy: 0.5056\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6711 - accuracy: 0.5883 - val_loss: 0.7025 - val_accuracy: 0.4988\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6691 - accuracy: 0.5900 - val_loss: 0.7033 - val_accuracy: 0.5025\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6680 - accuracy: 0.5888 - val_loss: 0.7061 - val_accuracy: 0.4994\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6673 - accuracy: 0.5942 - val_loss: 0.7100 - val_accuracy: 0.4944\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6674 - accuracy: 0.5888 - val_loss: 0.7077 - val_accuracy: 0.5106\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6644 - accuracy: 0.5962 - val_loss: 0.7054 - val_accuracy: 0.5194\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6623 - accuracy: 0.6014 - val_loss: 0.7068 - val_accuracy: 0.5150\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.5989 - val_loss: 0.7136 - val_accuracy: 0.5150\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6617 - accuracy: 0.6034 - val_loss: 0.7101 - val_accuracy: 0.5025\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6604 - accuracy: 0.6058 - val_loss: 0.7124 - val_accuracy: 0.5188\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6605 - accuracy: 0.5952 - val_loss: 0.7127 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6597 - accuracy: 0.6112 - val_loss: 0.7123 - val_accuracy: 0.4981\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6606 - accuracy: 0.6108 - val_loss: 0.7138 - val_accuracy: 0.5188\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6571 - accuracy: 0.6077 - val_loss: 0.7144 - val_accuracy: 0.5094\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6529 - accuracy: 0.6211 - val_loss: 0.7192 - val_accuracy: 0.4938\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6504 - accuracy: 0.6273 - val_loss: 0.7265 - val_accuracy: 0.5038\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6521 - accuracy: 0.6167 - val_loss: 0.7192 - val_accuracy: 0.4981\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6511 - accuracy: 0.6166 - val_loss: 0.7214 - val_accuracy: 0.5025\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6500 - accuracy: 0.6264 - val_loss: 0.7266 - val_accuracy: 0.5019\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6506 - accuracy: 0.6180 - val_loss: 0.7201 - val_accuracy: 0.5013\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6506 - accuracy: 0.6162 - val_loss: 0.7235 - val_accuracy: 0.5019\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6467 - accuracy: 0.6223 - val_loss: 0.7196 - val_accuracy: 0.4850\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6492 - accuracy: 0.6222 - val_loss: 0.7222 - val_accuracy: 0.4981\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6462 - accuracy: 0.6202 - val_loss: 0.7233 - val_accuracy: 0.5019\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6438 - accuracy: 0.6267 - val_loss: 0.7254 - val_accuracy: 0.4969\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6453 - accuracy: 0.6230 - val_loss: 0.7260 - val_accuracy: 0.4969\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6431 - accuracy: 0.6253 - val_loss: 0.7278 - val_accuracy: 0.4956\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6408 - accuracy: 0.6295 - val_loss: 0.7353 - val_accuracy: 0.5025\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6425 - accuracy: 0.6255 - val_loss: 0.7227 - val_accuracy: 0.4988\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6410 - accuracy: 0.6323 - val_loss: 0.7279 - val_accuracy: 0.4900\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6383 - accuracy: 0.6344 - val_loss: 0.7262 - val_accuracy: 0.5106\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6374 - accuracy: 0.6372 - val_loss: 0.7381 - val_accuracy: 0.5019\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6370 - accuracy: 0.6386 - val_loss: 0.7271 - val_accuracy: 0.5006\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6355 - accuracy: 0.6350 - val_loss: 0.7317 - val_accuracy: 0.5050\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6292 - accuracy: 0.6416 - val_loss: 0.7331 - val_accuracy: 0.5075\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6309 - accuracy: 0.6488 - val_loss: 0.7271 - val_accuracy: 0.5119\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6320 - accuracy: 0.6375 - val_loss: 0.7353 - val_accuracy: 0.5188\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6332 - accuracy: 0.6375 - val_loss: 0.7376 - val_accuracy: 0.5038\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6265 - accuracy: 0.6466 - val_loss: 0.7333 - val_accuracy: 0.4994\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6325 - accuracy: 0.6372 - val_loss: 0.7325 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6296 - accuracy: 0.6473 - val_loss: 0.7398 - val_accuracy: 0.5069\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6239 - accuracy: 0.6473 - val_loss: 0.7449 - val_accuracy: 0.4956\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6298 - accuracy: 0.6425 - val_loss: 0.7401 - val_accuracy: 0.5063\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6259 - accuracy: 0.6528 - val_loss: 0.7419 - val_accuracy: 0.5075\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6238 - accuracy: 0.6441 - val_loss: 0.7371 - val_accuracy: 0.5188\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6217 - accuracy: 0.6506 - val_loss: 0.7455 - val_accuracy: 0.5125\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6221 - accuracy: 0.6459 - val_loss: 0.7407 - val_accuracy: 0.5138\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6282 - accuracy: 0.6470 - val_loss: 0.7382 - val_accuracy: 0.5131\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.6639 - val_loss: 0.7353 - val_accuracy: 0.5050\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6184 - accuracy: 0.6520 - val_loss: 0.7373 - val_accuracy: 0.5194\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6176 - accuracy: 0.6586 - val_loss: 0.7374 - val_accuracy: 0.5038\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6145 - accuracy: 0.6603 - val_loss: 0.7380 - val_accuracy: 0.5169\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6194 - accuracy: 0.6520 - val_loss: 0.7429 - val_accuracy: 0.5063\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6552 - val_loss: 0.7385 - val_accuracy: 0.5175\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.6595 - val_loss: 0.7429 - val_accuracy: 0.5094\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.6584 - val_loss: 0.7376 - val_accuracy: 0.5069\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6143 - accuracy: 0.6586 - val_loss: 0.7378 - val_accuracy: 0.5044\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6107 - accuracy: 0.6670 - val_loss: 0.7442 - val_accuracy: 0.5125\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6138 - accuracy: 0.6559 - val_loss: 0.7413 - val_accuracy: 0.5094\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.6614 - val_loss: 0.7447 - val_accuracy: 0.5088\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6104 - accuracy: 0.6589 - val_loss: 0.7569 - val_accuracy: 0.5013\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6031 - accuracy: 0.6622 - val_loss: 0.7466 - val_accuracy: 0.5088\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6148 - accuracy: 0.6591 - val_loss: 0.7461 - val_accuracy: 0.5156\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.6648 - val_loss: 0.7487 - val_accuracy: 0.5125\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6089 - accuracy: 0.6620 - val_loss: 0.7546 - val_accuracy: 0.5138\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6078 - accuracy: 0.6706 - val_loss: 0.7463 - val_accuracy: 0.5150\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6061 - accuracy: 0.6625 - val_loss: 0.7505 - val_accuracy: 0.5069\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6008 - accuracy: 0.6734 - val_loss: 0.7507 - val_accuracy: 0.5088\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6064 - accuracy: 0.6734 - val_loss: 0.7484 - val_accuracy: 0.5106\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6020 - accuracy: 0.6686 - val_loss: 0.7538 - val_accuracy: 0.5019\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6078 - accuracy: 0.6670 - val_loss: 0.7541 - val_accuracy: 0.5138\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5965 - accuracy: 0.6802 - val_loss: 0.7530 - val_accuracy: 0.5150\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6057 - accuracy: 0.6655 - val_loss: 0.7507 - val_accuracy: 0.5081\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5990 - accuracy: 0.6742 - val_loss: 0.7523 - val_accuracy: 0.5056\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5999 - accuracy: 0.6759 - val_loss: 0.7583 - val_accuracy: 0.5075\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5984 - accuracy: 0.6675 - val_loss: 0.7540 - val_accuracy: 0.5113\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5909 - accuracy: 0.6866 - val_loss: 0.7558 - val_accuracy: 0.5081\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5982 - accuracy: 0.6786 - val_loss: 0.7498 - val_accuracy: 0.5213\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.5916 - accuracy: 0.6862 - val_loss: 0.7545 - val_accuracy: 0.5188\n",
      "Epoch 99/100\n",
      " 68/200 [=========>....................] - ETA: 0s - loss: 0.5928 - accuracy: 0.6875"
     ]
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../mapped_dataset_Normalized_version.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
